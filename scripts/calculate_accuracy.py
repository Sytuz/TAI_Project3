"""
Calculate accuracy metrics for music identification results.
This script analyzes the output from batch music identification and calculates
various accuracy metrics, including the Top-K accuracy.
"""

import os
import sys
import csv
import re
import json
from pathlib import Path
from collections import defaultdict
import argparse

def extract_song_name(filename):
    """
    Extract the base song name from a filename.
    Handles various naming patterns:
    - sample_SongName_noise.wav -> SongName
    - sample_SongName_t30s.wav -> SongName  
    - SongName-Main-version.feat -> SongName
    - SongName.feat -> SongName
    """
    # Remove file extension
    name = Path(filename).stem
    
    # Remove common prefixes
    if name.startswith('sample_'):
        name = name[7:]  # Remove 'sample_'
    
    # Remove noise indicators
    name = re.sub(r'_(white|pink|brown)_noise$', '', name)
    
    # Remove feature extraction method suffixes like _spectral, _maxfreq first
    name = re.sub(r'_(spectral|maxfreq)$', '', name)
    
    # Remove timestamp indicators like _t30s, _t91s etc.
    name = re.sub(r'_t\d+s$', '', name)
    
    # Remove -Main-version suffix
    name = re.sub(r'-Main-version$', '', name)
    
    return name

def normalize_song_name(name):
    """
    Normalize song names for comparison by removing special characters,
    converting to lowercase, and standardizing spaces.
    """
    # Convert to lowercase
    name = name.lower()
    
    # Replace special characters with spaces
    name = re.sub(r'[^a-z0-9\s]', ' ', name)
    
    # Normalize multiple spaces to single space
    name = re.sub(r'\s+', ' ', name)
    
    # Strip whitespace
    name = name.strip()
    
    return name

def load_results_csv(filepath):
    """
    Load results from a CSV file generated by music_id.
    Returns (query_name, results_list) where results_list contains
    tuples of (rank, filename, ncd_score).
    """
    query_name = ""
    results = []
    
    with open(filepath, 'r') as f:
        lines = f.readlines()
    
    # Parse header information
    for line in lines:
        line = line.strip()
        if line.startswith('Query:'):
            query_name = line.split(':', 1)[1].strip()
        elif line.startswith('Rank,'):
            # Found the CSV header, break to start parsing data
            break
    
    # Parse CSV data
    csv_started = False
    for line in lines:
        line = line.strip()
        if line.startswith('Rank,'):
            csv_started = True
            continue
        
        if csv_started and line and not line.startswith('Query') and not line.startswith('Compressor'):
            parts = line.split(',')
            if len(parts) >= 3:
                try:
                    rank = int(parts[0])
                    filename = parts[1]
                    ncd_score = float(parts[2])
                    results.append((rank, filename, ncd_score))
                except (ValueError, IndexError):
                    continue
    
    return query_name, results

def calculate_accuracy_metrics(results_dir, output_file=None):
    """
    Calculate various accuracy metrics from batch identification results.
    """
    print(f"Analyzing results in: {results_dir}")
    
    # Find all result CSV files
    result_files = list(Path(results_dir).glob("*_results.csv"))
    
    if not result_files:
        print("Error: No result CSV files found in the directory")
        return
    
    print(f"Found {len(result_files)} result files")
    
    # Metrics tracking
    total_queries = 0
    top1_correct = 0
    top5_correct = 0
    top10_correct = 0
    
    detailed_results = []
    
    # Process each result file
    for result_file in result_files:
        try:
            query_name, results = load_results_csv(result_file)
            
            if not results:
                print(f"Warning: No results found in {result_file}")
                continue
            
            # Extract ground truth from query name
            ground_truth = normalize_song_name(extract_song_name(query_name))
            
            if not ground_truth:
                print(f"Warning: Could not extract ground truth from query: {query_name}")
                continue
            
            total_queries += 1
            
            # Check if ground truth appears in top-K results
            found_at_rank = None
            
            for rank, filename, ncd_score in results:
                candidate = normalize_song_name(extract_song_name(filename))
                
                if ground_truth == candidate:
                    found_at_rank = rank
                    break
            
            # Update metrics
            if found_at_rank is not None:
                if found_at_rank <= 1:
                    top1_correct += 1
                if found_at_rank <= 5:
                    top5_correct += 1
                if found_at_rank <= 10:
                    top10_correct += 1
            
            # Store detailed result
            top_match = results[0] if results else (0, "None", float('inf'))
            top_match_song = normalize_song_name(extract_song_name(top_match[1])) if results else ""
            is_top_match_correct = (ground_truth == top_match_song) if results else False
            
            detailed_results.append({
                'query': query_name,
                'ground_truth': ground_truth,
                'top_match': extract_song_name(top_match[1]) if results else "None",
                'top_match_ncd': top_match[2] if results else float('inf'),
                'found_at_rank': found_at_rank,
                'correct': is_top_match_correct
            })
            
            # Print progress
            status = "✓" if found_at_rank is not None else "✗"
            rank_info = f"(rank {found_at_rank})" if found_at_rank is not None else "(not found)"
            print(f"{status} {query_name} -> {ground_truth} {rank_info}")
            
        except Exception as e:
            print(f"Error processing {result_file}: {e}")
            continue
    
    # Calculate final metrics
    if total_queries > 0:
        top1_accuracy = (top1_correct / total_queries) * 100
        top5_accuracy = (top5_correct / total_queries) * 100
        top10_accuracy = (top10_correct / total_queries) * 100
        
        # Print summary
        print("\n" + "="*50)
        print("ACCURACY METRICS SUMMARY")
        print("="*50)
        print(f"Total queries processed: {total_queries}")
        print(f"Top-1 Accuracy: {top1_correct}/{total_queries} ({top1_accuracy:.1f}%)")
        print(f"Top-5 Accuracy: {top5_correct}/{total_queries} ({top5_accuracy:.1f}%)")
        print(f"Top-10 Accuracy: {top10_correct}/{total_queries} ({top10_accuracy:.1f}%)")
        
        # Prepare output data
        summary = {
            'total_queries': total_queries,
            'top1_correct': top1_correct,
            'top5_correct': top5_correct,
            'top10_correct': top10_correct,
            'top1_accuracy': top1_accuracy,
            'top5_accuracy': top5_accuracy,
            'top10_accuracy': top10_accuracy,
            'detailed_results': detailed_results
        }
        
        # Save to file if specified
        if output_file:
            with open(output_file, 'w') as f:
                json.dump(summary, f, indent=2)
            print(f"\nDetailed results saved to: {output_file}")
        
        return summary
    else:
        print("Error: No valid queries were processed")
        return None

def main():
    parser = argparse.ArgumentParser(description='Calculate accuracy metrics for music identification results')
    parser.add_argument('results_dir', help='Directory containing *_results.csv files')
    parser.add_argument('-o', '--output', help='Output JSON file for detailed results')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.results_dir):
        print(f"Error: Results directory does not exist: {args.results_dir}")
        sys.exit(1)
    
    calculate_accuracy_metrics(args.results_dir, args.output)

if __name__ == "__main__":
    main()
